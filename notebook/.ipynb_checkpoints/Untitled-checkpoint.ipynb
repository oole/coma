{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "royal-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quality-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "endangered-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train\n",
    "images = images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precise-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "similar-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "declared-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-visibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-album",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "emotional-capital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(images[:1])\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "interracial-school",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = tf.nn.softmax(predictions)\n",
    "softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dirty-welding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05451572, 0.09808242, 0.13330501, 0.02449886, 0.11688536,\n",
       "       0.13131924, 0.17186493, 0.0721596 , 0.12615988, 0.07120895],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "above-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daily-baker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6421368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(labels[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "shaped-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "removed-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 797us/step - loss: 0.6876 - accuracy: 0.7579\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.4087 - accuracy: 0.8527\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.3713 - accuracy: 0.8639\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.3494 - accuracy: 0.8701\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.3328 - accuracy: 0.8765\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.3147 - accuracy: 0.8819\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.3092 - accuracy: 0.8826\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.2910 - accuracy: 0.8916\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.2866 - accuracy: 0.8934\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.2805 - accuracy: 0.8969\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.2793 - accuracy: 0.8944\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.2665 - accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.2650 - accuracy: 0.9002\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.2596 - accuracy: 0.9013\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.2511 - accuracy: 0.9036\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 800us/step - loss: 0.2532 - accuracy: 0.9056\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 1s 790us/step - loss: 0.2433 - accuracy: 0.9066\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.2399 - accuracy: 0.9079\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2339 - accuracy: 0.9117\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.2332 - accuracy: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe99f606df0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images, labels, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "centered-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.2337 - accuracy: 0.9119\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.2322 - accuracy: 0.9116\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.2287 - accuracy: 0.9138\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.2249 - accuracy: 0.9154\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.2184 - accuracy: 0.9169\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 1s 793us/step - loss: 0.2184 - accuracy: 0.9170\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.2168 - accuracy: 0.9178\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.2139 - accuracy: 0.9176\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.2108 - accuracy: 0.9211\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2113 - accuracy: 0.9190\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 1s 792us/step - loss: 0.2056 - accuracy: 0.9225\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.2047 - accuracy: 0.9219\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.2039 - accuracy: 0.9218\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.2020 - accuracy: 0.9226\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.1964 - accuracy: 0.9248\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.1968 - accuracy: 0.9244\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.1960 - accuracy: 0.9247\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1950 - accuracy: 0.9249\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 802us/step - loss: 0.1930 - accuracy: 0.9261\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.1916 - accuracy: 0.9273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8b0079c40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images, labels, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bibliographic-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img, test_labels = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "extreme-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 84.3079 - accuracy: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[84.30786895751953, 0.8603000044822693]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "precious-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mfashion.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mfashion.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "chinese-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"mfashion_weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "burning-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe8604a00a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"mfashion_weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "higher-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.keras.models.load_model(\"mfashion.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hindu-demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 792us/step - loss: 0.1892 - accuracy: 0.9277\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.1859 - accuracy: 0.9294\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.1848 - accuracy: 0.9296\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.1845 - accuracy: 0.9301\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.1815 - accuracy: 0.9312\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.1840 - accuracy: 0.9300\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.1783 - accuracy: 0.9314\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 1s 800us/step - loss: 0.1810 - accuracy: 0.9307\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.1772 - accuracy: 0.9319\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.1746 - accuracy: 0.9319\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 804us/step - loss: 0.1770 - accuracy: 0.9320\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.1696 - accuracy: 0.9340\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 804us/step - loss: 0.1724 - accuracy: 0.9338\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.1698 - accuracy: 0.9351\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.1697 - accuracy: 0.9350\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 804us/step - loss: 0.1692 - accuracy: 0.9342\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 804us/step - loss: 0.1652 - accuracy: 0.9358\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 830us/step - loss: 0.1646 - accuracy: 0.9372\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.1673 - accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 807us/step - loss: 0.1621 - accuracy: 0.9368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe85937e220>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.fit(images, labels, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "three-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 84.3079 - accuracy: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[84.30786895751953, 0.8603000044822693]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "macro-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing it with tf.data.Dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Now doing it with tf.data.Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "imperial-fortune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28), (None,)), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "train_ds.shuffle(10000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "serious-grenada",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-59eb4dc08ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-handling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
